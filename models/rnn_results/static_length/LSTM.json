{"stat_models": [{"loss": [1.791023850440979, 1.7926963567733765, 1.7881827354431152, 1.7852678298950195, 1.783279538154602, 1.783878207206726, 1.778659701347351, 1.7709360122680664, 1.776979684829712, 1.770690679550171, 1.7669965028762817, 1.7635431289672852, 1.7665868997573853, 1.756596326828003, 1.7483718395233154, 1.7582578659057617, 1.7487635612487793, 1.743760108947754, 1.7373658418655396, 1.7426248788833618, 1.7257049083709717, 1.716186761856079, 1.7313001155853271, 1.7158781290054321, 1.7065622806549072, 1.6941555738449097, 1.700755000114441, 1.6701432466506958, 1.6544424295425415, 1.6755319833755493, 1.6461316347122192, 1.62372624874115, 1.5862900018692017, 1.594490647315979, 1.5198701620101929, 1.4920108318328857, 1.5431610345840454, 1.4818825721740723, 1.4427226781845093, 1.384418249130249, 1.4634593725204468, 1.3132431507110596, 1.322283148765564, 1.548228144645691, 1.423148512840271, 1.406851053237915, 1.3306418657302856, 1.4542425870895386, 1.2741003036499023, 1.3078639507293701, 1.5270205736160278, 1.385906457901001, 1.394944429397583, 1.3147234916687012, 1.427483320236206, 1.2914440631866455, 1.314874529838562, 1.4981657266616821, 1.368680715560913, 1.38271963596344, 1.3083890676498413, 1.4087103605270386, 1.2904081344604492, 1.304392695426941, 1.4693228006362915, 1.3642045259475708, 1.375963568687439, 1.303971290588379, 1.3998277187347412, 1.2812479734420776, 1.2961231470108032, 1.4580528736114502, 1.3626203536987305, 1.3704092502593994, 1.2977564334869385, 1.3980712890625, 1.2727289199829102, 1.288887619972229, 1.4554405212402344, 1.3495866060256958, 1.3660471439361572, 1.2884018421173096, 1.389744520187378, 1.2654601335525513, 1.2808752059936523, 1.451832890510559, 1.3416969776153564, 1.3621702194213867, 1.2762669324874878, 1.3793781995773315, 1.257830023765564, 1.2777045965194702, 1.435408592224121, 1.3307386636734009, 1.353162407875061, 1.27100670337677, 1.370690941810608, 1.2482962608337402, 1.2626614570617676, 1.4294284582138062, 1.3279433250427246, 1.3458882570266724, 1.2622451782226562, 1.3722935914993286, 1.2364201545715332, 1.2506465911865234, 1.4135823249816895, 1.319562554359436, 1.33452308177948, 1.2564386129379272, 1.370259404182434, 1.230515956878662, 1.238420844078064, 1.4050228595733643, 1.3118499517440796, 1.318671464920044, 1.2482140064239502, 1.365577220916748, 1.2167274951934814, 1.2168010473251343, 1.393545150756836, 1.305734634399414, 1.3109114170074463, 1.2381870746612549, 1.3620762825012207, 1.2203353643417358, 1.2134544849395752, 1.384438395500183, 1.298537254333496, 1.307539463043213, 1.220690369606018, 1.3648768663406372, 1.2096645832061768, 1.2256629467010498, 1.3920611143112183, 1.293567180633545, 1.3106993436813354, 1.2242234945297241, 1.359511137008667, 1.2147855758666992, 1.18746018409729, 1.3770346641540527, 1.2939364910125732, 1.289463996887207, 1.2124571800231934, 1.3505170345306396, 1.2047308683395386, 1.1856651306152344, 1.37730872631073, 1.2835149765014648, 1.2954176664352417, 1.204066514968872, 1.3396738767623901, 1.2024455070495605, 1.1793478727340698, 1.359887957572937, 1.2764310836791992, 1.2885798215866089, 1.1955660581588745, 1.3380264043807983, 1.2035356760025024, 1.177270770072937, 1.351984977722168, 1.2591426372528076, 1.2787457704544067, 1.2005419731140137, 1.3457229137420654, 1.1785942316055298, 1.1715503931045532, 1.3565754890441895, 1.2703551054000854, 1.2953596115112305, 1.1842297315597534, 1.332573413848877, 1.1786985397338867, 1.2034432888031006, 1.3633575439453125, 1.2607783079147339, 1.2816832065582275, 1.193182349205017, 1.3419609069824219, 1.1864758729934692, 1.1567838191986084, 1.35318922996521, 1.273393154144287, 1.2731471061706543, 1.1705176830291748, 1.3114337921142578, 1.1870604753494263, 1.1633927822113037, 1.3463164567947388, 1.2532985210418701, 1.2617217302322388, 1.162656545639038, 1.3178167343139648, 1.1573818922042847, 1.1538538932800293, 1.3476970195770264, 1.2326017618179321, 1.2643462419509888, 1.146425485610962, 1.306257724761963, 1.154899001121521, 1.1731514930725098, 1.3539358377456665, 1.2284142971038818, 1.2632867097854614, 1.1799286603927612, 1.3061503171920776, 1.1588716506958008], "training_accuracy": [0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.421875, 0.453125, 0.4296875, 0.4375, 0.4765625, 0.46875, 0.46875, 0.484375, 0.4609375, 0.484375, 0.53125, 0.515625, 0.5390625, 0.5078125, 0.5078125, 0.484375, 0.546875, 0.546875, 0.5390625, 0.5], "validation_accuracy": [0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4797297297297297, 0.4391891891891892, 0.5, 0.41216216216216217, 0.3783783783783784, 0.3783783783783784, 0.3783783783783784, 0.3716216216216216, 0.39864864864864863, 0.43243243243243246, 0.3918918918918919, 0.36486486486486486, 0.3716216216216216, 0.3716216216216216, 0.36486486486486486, 0.3783783783783784, 0.3783783783783784, 0.36486486486486486, 0.3716216216216216, 0.3918918918918919], "validation_loss": [1.7863560914993286, 1.765612244606018, 1.7408229112625122, 1.7034865617752075, 1.622140645980835, 1.3935151100158691, 1.2446720600128174, 1.2316060066223145, 1.238289475440979, 1.2319495677947998, 1.2339099645614624, 1.2312184572219849, 1.2260727882385254, 1.2308661937713623, 1.2319045066833496, 1.2362974882125854, 1.2455013990402222, 1.2569987773895264, 1.2545652389526367, 1.227308988571167, 1.2586249113082886, 1.2807246446609497, 1.2988332509994507, 1.3047449588775635, 1.3308743238449097, 1.2545379400253296, 1.284386396408081, 1.3241302967071533, 1.3329830169677734, 1.2965819835662842], "test_accuracy": 0.3783783783783784, "other_comments": null, "model_structure": "LSTM with 60 timesteps, 200 hidden units, 5 layer, 30 epochs,  batch size of 128, learning rate of 0.0001, with static length of data and pre_padding type."}, {"loss": [1.8195044994354248, 1.8204612731933594, 1.8225904703140259, 1.7972999811172485, 1.822201132774353, 1.8084006309509277, 1.8071669340133667, 1.801448941230774, 1.8019700050354004, 1.8022942543029785, 1.7807424068450928, 1.7997785806655884, 1.7877914905548096, 1.7861337661743164, 1.7813462018966675, 1.7809741497039795, 1.7784621715545654, 1.7604784965515137, 1.7712643146514893, 1.7607483863830566, 1.7588815689086914, 1.7537221908569336, 1.7502213716506958, 1.7416250705718994, 1.7292900085449219, 1.7249302864074707, 1.7124582529067993, 1.7065539360046387, 1.701406478881836, 1.6879063844680786, 1.6587655544281006, 1.6580522060394287, 1.6086366176605225, 1.5856081247329712, 1.5693442821502686, 1.5529100894927979, 1.5224649906158447, 1.4358603954315186, 1.5027379989624023, 1.348514437675476, 1.368554711341858, 1.3962985277175903, 1.4270497560501099, 1.4217655658721924, 1.345805287361145, 1.4687505960464478, 1.2656127214431763, 1.3515501022338867, 1.3921128511428833, 1.414831280708313, 1.4002941846847534, 1.3453539609909058, 1.4157054424285889, 1.2438037395477295, 1.3431328535079956, 1.3724370002746582, 1.3940590620040894, 1.3674683570861816, 1.334316372871399, 1.3976036310195923, 1.236159324645996, 1.3435419797897339, 1.357627034187317, 1.379529356956482, 1.3597967624664307, 1.3254808187484741, 1.3966766595840454, 1.2343095541000366, 1.3316168785095215, 1.346759557723999, 1.3640000820159912, 1.356889009475708, 1.3133249282836914, 1.3968793153762817, 1.2241454124450684, 1.3129287958145142, 1.3306752443313599, 1.3531897068023682, 1.363576889038086, 1.3057217597961426, 1.3893693685531616, 1.2215157747268677, 1.3040482997894287, 1.3159180879592896, 1.3460900783538818, 1.3606847524642944, 1.2984915971755981, 1.3900091648101807, 1.2127903699874878, 1.2962442636489868, 1.3078465461730957, 1.3341426849365234, 1.3600832223892212, 1.289919376373291, 1.3881882429122925, 1.2086580991744995, 1.2911666631698608, 1.3037043809890747, 1.3328838348388672, 1.354398488998413, 1.2841023206710815, 1.3801932334899902, 1.1995069980621338, 1.2857630252838135, 1.298473596572876, 1.3307874202728271, 1.3545840978622437, 1.2813479900360107, 1.3831027746200562, 1.193617343902588, 1.286997675895691, 1.2979029417037964, 1.3253711462020874, 1.3495599031448364, 1.2759915590286255, 1.382247805595398, 1.1964293718338013, 1.282769799232483, 1.292663335800171, 1.3223073482513428, 1.351108193397522, 1.271733045578003, 1.3781099319458008, 1.1972652673721313, 1.2782670259475708, 1.2899237871170044, 1.322048306465149, 1.343576192855835, 1.266595482826233, 1.3787050247192383, 1.1950956583023071, 1.2730759382247925, 1.2878302335739136, 1.3133050203323364, 1.3462231159210205, 1.2659229040145874, 1.3814234733581543, 1.1923762559890747, 1.2735226154327393, 1.2894344329833984, 1.3140225410461426, 1.341176986694336, 1.2641500234603882, 1.3819501399993896, 1.192521095275879, 1.270348072052002, 1.2786667346954346, 1.3117516040802002, 1.336927890777588, 1.2652617692947388, 1.3743321895599365, 1.1862550973892212, 1.2746775150299072, 1.2822829484939575, 1.306641697883606, 1.3273786306381226, 1.2590093612670898, 1.3736560344696045, 1.1885242462158203, 1.2682145833969116, 1.2765599489212036, 1.3119670152664185, 1.3327544927597046, 1.2598174810409546, 1.369997501373291, 1.18471360206604, 1.263290524482727, 1.280448079109192, 1.308760643005371, 1.3288042545318604, 1.2646242380142212, 1.3711292743682861, 1.1902395486831665, 1.2604587078094482, 1.2714741230010986, 1.3001904487609863, 1.323598027229309, 1.2585986852645874, 1.3773475885391235, 1.1830499172210693, 1.2535125017166138, 1.2691506147384644, 1.2963088750839233, 1.3297123908996582, 1.2612206935882568, 1.3614436388015747, 1.1785701513290405, 1.2554216384887695, 1.262029767036438, 1.2899179458618164, 1.3184438943862915, 1.2520415782928467, 1.3692975044250488, 1.1781346797943115, 1.2439358234405518, 1.2569608688354492, 1.2876372337341309, 1.3148221969604492, 1.2438874244689941, 1.360755205154419, 1.1765758991241455, 1.2407121658325195, 1.2503381967544556, 1.2847706079483032, 1.307056188583374, 1.2438063621520996, 1.3661956787109375, 1.1728328466415405, 1.227509617805481, 1.2460664510726929], "training_accuracy": [0.03125, 0.3125, 0.3125, 0.3125, 0.3203125, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.375, 0.3828125, 0.3359375, 0.390625, 0.375, 0.375, 0.3984375, 0.34375, 0.359375, 0.390625, 0.328125, 0.375, 0.359375, 0.3828125, 0.3671875, 0.359375, 0.359375], "validation_accuracy": [0.0, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.23015873015873015, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.40476190476190477, 0.3888888888888889, 0.38095238095238093, 0.38095238095238093, 0.3888888888888889, 0.3888888888888889, 0.40476190476190477, 0.40476190476190477, 0.3968253968253968, 0.40476190476190477, 0.40476190476190477, 0.3968253968253968, 0.3968253968253968, 0.3888888888888889, 0.3968253968253968, 0.3968253968253968, 0.4126984126984127], "validation_loss": [1.82421875, 1.806018590927124, 1.7856954336166382, 1.7569968700408936, 1.7009159326553345, 1.5687919855117798, 1.47579824924469, 1.402521014213562, 1.3308429718017578, 1.313567042350769, 1.3311907052993774, 1.3573466539382935, 1.3711894750595093, 1.3691836595535278, 1.3647301197052002, 1.3647252321243286, 1.3662232160568237, 1.3684450387954712, 1.3712440729141235, 1.3705496788024902, 1.3685394525527954, 1.3652361631393433, 1.3598169088363647, 1.357491374015808, 1.3561413288116455, 1.3492238521575928, 1.3480180501937866, 1.339516520500183, 1.3358570337295532, 1.3318899869918823], "test_accuracy": 0.42857142857142855, "other_comments": null, "model_structure": "LSTM with 60 timesteps, 200 hidden units, 5 layer, 30 epochs,  batch size of 128, learning rate of 0.0001, with static length of data and pre_padding type."}, {"loss": [1.7726579904556274, 1.7668780088424683, 1.76666259765625, 1.7600376605987549, 1.7594815492630005, 1.755006194114685, 1.7591358423233032, 1.774019479751587, 1.7564380168914795, 1.7468178272247314, 1.7485929727554321, 1.738594889640808, 1.7414249181747437, 1.7343993186950684, 1.7410304546356201, 1.7546391487121582, 1.740422010421753, 1.7246918678283691, 1.7281161546707153, 1.7119026184082031, 1.7187423706054688, 1.706769347190857, 1.716263771057129, 1.7305960655212402, 1.7148994207382202, 1.6896014213562012, 1.6918516159057617, 1.6647177934646606, 1.6741851568222046, 1.6496267318725586, 1.6660617589950562, 1.6647800207138062, 1.6511609554290771, 1.6043087244033813, 1.5944703817367554, 1.536804437637329, 1.5489953756332397, 1.4880552291870117, 1.5318529605865479, 1.453154444694519, 1.5184316635131836, 1.4071526527404785, 1.427980661392212, 1.317812442779541, 1.412052035331726, 1.3432137966156006, 1.444796085357666, 1.6828477382659912, 1.503003478050232, 1.3259236812591553, 1.391938328742981, 1.2752625942230225, 1.368881344795227, 1.3202682733535767, 1.4103244543075562, 1.5519773960113525, 1.4331165552139282, 1.3131129741668701, 1.3736647367477417, 1.2911356687545776, 1.3521164655685425, 1.325865387916565, 1.4155309200286865, 1.4210524559020996, 1.427140235900879, 1.3208545446395874, 1.3733899593353271, 1.2869272232055664, 1.3501650094985962, 1.3256338834762573, 1.4095662832260132, 1.3184442520141602, 1.436377763748169, 1.316590428352356, 1.3716899156570435, 1.2696905136108398, 1.3390426635742188, 1.3143309354782104, 1.404361367225647, 1.2590439319610596, 1.4446781873703003, 1.3061670064926147, 1.36316978931427, 1.2529419660568237, 1.3331342935562134, 1.3070842027664185, 1.3972468376159668, 1.2427910566329956, 1.4420225620269775, 1.2956880331039429, 1.3589526414871216, 1.2472695112228394, 1.3188581466674805, 1.3049026727676392, 1.3992754220962524, 1.1808013916015625, 1.4306942224502563, 1.2893481254577637, 1.3504629135131836, 1.249581217765808, 1.3127238750457764, 1.299343466758728, 1.398268699645996, 1.1026842594146729, 1.4285205602645874, 1.2913975715637207, 1.35191810131073, 1.2413519620895386, 1.3048285245895386, 1.2942008972167969, 1.395664095878601, 1.0853822231292725, 1.428721308708191, 1.2873862981796265, 1.3506845235824585, 1.2372580766677856, 1.2993136644363403, 1.2901928424835205, 1.3914235830307007, 1.041988492012024, 1.4309254884719849, 1.2789021730422974, 1.3535624742507935, 1.2309191226959229, 1.2907781600952148, 1.2802152633666992, 1.3907830715179443, 0.9733707904815674, 1.424064040184021, 1.27321457862854, 1.3511039018630981, 1.2217283248901367, 1.2828712463378906, 1.2798922061920166, 1.385583519935608, 0.9986417293548584, 1.4240368604660034, 1.2702195644378662, 1.353575348854065, 1.219032883644104, 1.2805571556091309, 1.2721991539001465, 1.3785734176635742, 0.9418807625770569, 1.4098448753356934, 1.2567459344863892, 1.3464583158493042, 1.2081596851348877, 1.2633923292160034, 1.265260100364685, 1.3676491975784302, 0.9341740012168884, 1.4037408828735352, 1.2519407272338867, 1.3388032913208008, 1.2033143043518066, 1.2715117931365967, 1.256221890449524, 1.365693211555481, 0.8594121336936951, 1.4071619510650635, 1.2433103322982788, 1.3382742404937744, 1.1988513469696045, 1.2517368793487549, 1.2475632429122925, 1.3575584888458252, 0.8570544123649597, 1.3980236053466797, 1.228774905204773, 1.3243814706802368, 1.1872332096099854, 1.2586675882339478, 1.238051176071167, 1.3554191589355469, 0.817349374294281, 1.392796277999878, 1.2290897369384766, 1.3298404216766357, 1.1932326555252075, 1.2382384538650513, 1.235457420349121, 1.3535239696502686, 0.766805112361908, 1.3819537162780762, 1.2087528705596924, 1.3244545459747314, 1.1750932931900024, 1.2505898475646973, 1.2272249460220337, 1.3349636793136597, 0.68953537940979, 1.3752529621124268, 1.207045555114746, 1.3182168006896973, 1.1748446226119995, 1.2234063148498535, 1.2297028303146362, 1.3367856740951538, 0.6817094683647156, 1.3638784885406494, 1.2121930122375488, 1.290044903755188, 1.1628578901290894, 1.2370715141296387, 1.2114489078521729, 1.3367317914962769, 0.6159414649009705, 1.3515931367874146, 1.190598726272583, 1.2947534322738647, 1.1606477499008179, 1.2247048616409302, 1.2205703258514404, 1.326209545135498, 0.5797336101531982, 1.3443138599395752, 1.191080927848816, 1.2717748880386353, 1.1501989364624023, 1.2230411767959595, 1.219080924987793, 1.3414433002471924, 0.536782443523407, 1.3346381187438965, 1.1737233400344849, 1.2397072315216064, 1.1524896621704102, 1.240478277206421, 1.2106930017471313, 1.3314790725708008, 0.48872750997543335, 1.3209388256072998, 1.1794531345367432, 1.2722768783569336, 1.1398292779922485, 1.229369044303894, 1.2029731273651123, 1.3382673263549805, 0.4513232111930847], "training_accuracy": [0.21875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3046875, 0.3125, 0.359375, 0.3671875, 0.359375, 0.3828125, 0.3828125, 0.40625, 0.4140625, 0.390625, 0.3984375], "validation_accuracy": [0.2222222222222222, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.3888888888888889, 0.37962962962962965, 0.39814814814814814, 0.39814814814814814, 0.37962962962962965, 0.3888888888888889, 0.39814814814814814, 0.3611111111111111, 0.39814814814814814, 0.4074074074074074, 0.39814814814814814, 0.3611111111111111], "validation_loss": [1.7646024227142334, 1.7450013160705566, 1.7244837284088135, 1.69325852394104, 1.621423602104187, 1.4399462938308716, 1.3226484060287476, 1.3105453252792358, 1.3311516046524048, 1.328140377998352, 1.3158011436462402, 1.3092674016952515, 1.3126654624938965, 1.3145591020584106, 1.3146470785140991, 1.32007896900177, 1.318271517753601, 1.3225898742675781, 1.309975266456604, 1.3052780628204346, 1.2993265390396118, 1.2898404598236084, 1.2856768369674683, 1.2771692276000977, 1.2703999280929565, 1.295348882675171, 1.2565648555755615, 1.2710866928100586, 1.2758269309997559, 1.3004881143569946], "test_accuracy": 0.35185185185185186, "other_comments": null, "model_structure": "LSTM with 60 timesteps, 200 hidden units, 5 layer, 30 epochs,  batch size of 128, learning rate of 0.0001, with static length of data and pre_padding type."}, {"loss": [1.7866642475128174, 1.7885926961898804, 1.7809065580368042, 1.7861508131027222, 1.782562255859375, 1.7828655242919922, 1.7791987657546997, 1.7682856321334839, 1.7717722654342651, 1.7634117603302002, 1.7693203687667847, 1.76485276222229, 1.7658308744430542, 1.7594428062438965, 1.7491117715835571, 1.752420425415039, 1.742377758026123, 1.7491605281829834, 1.7423295974731445, 1.7443517446517944, 1.7326933145523071, 1.7216469049453735, 1.7239035367965698, 1.710876703262329, 1.7171571254730225, 1.7056776285171509, 1.7071592807769775, 1.684610366821289, 1.6681493520736694, 1.6656888723373413, 1.641532301902771, 1.6422332525253296, 1.615439772605896, 1.6110996007919312, 1.55615234375, 1.5266097784042358, 1.503890037536621, 1.4655859470367432, 1.4722577333450317, 1.4450805187225342, 1.4730757474899292, 1.3752033710479736, 1.3623936176300049, 1.428913950920105, 1.3824738264083862, 1.4598851203918457, 1.4166606664657593, 1.4920613765716553, 1.3319852352142334, 1.31029212474823, 1.399229884147644, 1.3613656759262085, 1.423810362815857, 1.394438624382019, 1.460279941558838, 1.3284541368484497, 1.2992795705795288, 1.3679249286651611, 1.3443176746368408, 1.3837400674819946, 1.3793830871582031, 1.4117728471755981, 1.3325656652450562, 1.3139424324035645, 1.3466823101043701, 1.3414490222930908, 1.368363380432129, 1.3696669340133667, 1.3846327066421509, 1.3282917737960815, 1.312436819076538, 1.3440446853637695, 1.33747136592865, 1.361372470855713, 1.3641033172607422, 1.375239610671997, 1.316917061805725, 1.3017486333847046, 1.3381491899490356, 1.3328713178634644, 1.3570761680603027, 1.3524948358535767, 1.37604558467865, 1.3046252727508545, 1.3002114295959473, 1.325434684753418, 1.3241159915924072, 1.3483970165252686, 1.3559068441390991, 1.36222505569458, 1.3075019121170044, 1.2981834411621094, 1.3157844543457031, 1.3160403966903687, 1.3359867334365845, 1.3541160821914673, 1.3558783531188965, 1.3048697710037231, 1.2871979475021362, 1.3086023330688477, 1.3125256299972534, 1.327359914779663, 1.3523927927017212, 1.3450349569320679, 1.2942079305648804, 1.2803435325622559, 1.3017905950546265, 1.312063217163086, 1.3199599981307983, 1.3486279249191284, 1.3338727951049805, 1.2923301458358765, 1.272862195968628, 1.2958965301513672, 1.3084454536437988, 1.313033938407898, 1.3406124114990234, 1.3265165090560913, 1.292653203010559, 1.2616530656814575, 1.2855883836746216, 1.3039216995239258, 1.3063530921936035, 1.3412190675735474, 1.3191430568695068, 1.2805112600326538, 1.2521288394927979, 1.2772341966629028, 1.3045680522918701, 1.3010544776916504, 1.3392906188964844, 1.3142567873001099, 1.27131986618042, 1.248504638671875, 1.270822525024414, 1.2993227243423462, 1.2954211235046387, 1.3287311792373657, 1.2992116212844849, 1.2721132040023804, 1.2446762323379517, 1.2679897546768188, 1.2901362180709839, 1.2911498546600342, 1.3206080198287964, 1.3070694208145142, 1.2446757555007935, 1.2365012168884277, 1.2522386312484741, 1.2874654531478882, 1.2943577766418457, 1.3096314668655396, 1.2915481328964233, 1.2614483833312988, 1.2352553606033325, 1.2574434280395508, 1.2813692092895508, 1.2826261520385742, 1.324462652206421, 1.2934925556182861, 1.2384657859802246, 1.222919225692749, 1.2474205493927002, 1.2716798782348633, 1.2757487297058105, 1.2971585988998413, 1.2777321338653564, 1.223486304283142, 1.2133089303970337, 1.2371011972427368, 1.2645853757858276, 1.2869738340377808, 1.2964951992034912, 1.2691861391067505, 1.218430995941162, 1.2017236948013306, 1.2264573574066162, 1.2563295364379883, 1.277646541595459, 1.2850594520568848, 1.2628103494644165, 1.2147817611694336, 1.2221696376800537, 1.233605980873108, 1.2401560544967651, 1.2719948291778564, 1.282367467880249, 1.2584829330444336, 1.2046185731887817, 1.1927647590637207, 1.2211569547653198, 1.2320369482040405, 1.2740485668182373, 1.2722934484481812, 1.2551437616348267, 1.2057101726531982, 1.1871705055236816, 1.2268767356872559, 1.2297035455703735, 1.2793885469436646, 1.2824616432189941, 1.2628456354141235, 1.189155101776123, 1.1983036994934082, 1.236046552658081, 1.2114720344543457, 1.2584301233291626, 1.2804689407348633, 1.242525577545166, 1.2050107717514038], "training_accuracy": [0.2890625, 0.4140625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.390625, 0.3984375, 0.421875, 0.3984375, 0.40625, 0.4140625, 0.40625, 0.4140625, 0.40625, 0.4375, 0.4609375, 0.453125, 0.4375, 0.4375, 0.4453125], "validation_accuracy": [0.16058394160583941, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.43795620437956206, 0.49635036496350365, 0.5036496350364964, 0.5036496350364964, 0.5036496350364964, 0.5036496350364964, 0.45985401459854014, 0.40145985401459855, 0.44525547445255476, 0.3722627737226277, 0.3722627737226277, 0.3795620437956204, 0.3722627737226277, 0.3795620437956204, 0.35036496350364965], "validation_loss": [1.7903470993041992, 1.76981520652771, 1.7460976839065552, 1.7109812498092651, 1.6354496479034424, 1.428044080734253, 1.2670116424560547, 1.243720531463623, 1.2533899545669556, 1.260805606842041, 1.2435598373413086, 1.227881669998169, 1.2263836860656738, 1.2280222177505493, 1.220809817314148, 1.2135815620422363, 1.2122148275375366, 1.2167253494262695, 1.2172304391860962, 1.2170575857162476, 1.2115148305892944, 1.2138476371765137, 1.223608374595642, 1.2137022018432617, 1.234649896621704, 1.2433167695999146, 1.2375946044921875, 1.2457671165466309, 1.2482258081436157, 1.2796887159347534], "test_accuracy": 0.3284671532846715, "other_comments": null, "model_structure": "LSTM with 60 timesteps, 200 hidden units, 5 layer, 30 epochs,  batch size of 128, learning rate of 0.0001, with static length of data and pre_padding type."}], "validation_mean_accuracy": 0.4516399219866374, "test_mean_accuracy": 0.37181720302158255, "predictionResults": [[true, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false], [true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true], [false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false], [false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false]]}